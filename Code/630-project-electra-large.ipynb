{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-04-23T05:24:21.155164Z",
     "iopub.status.busy": "2024-04-23T05:24:21.154410Z",
     "iopub.status.idle": "2024-04-23T05:25:20.161552Z",
     "shell.execute_reply": "2024-04-23T05:25:20.160737Z",
     "shell.execute_reply.started": "2024-04-23T05:24:21.155123Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install spacy\n",
    "# !pip install wandb\n",
    "# !python -m spacy download en_core_web_sm\n",
    "# !pip install datasets\n",
    "# !pip install transformers[torch]\n",
    "# !pip install evaluate\n",
    "# !pip install seqeval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/aryanrr/.netrc\r\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import spacy\n",
    "import random\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, precision_recall_fscore_support\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import silhouette_score\n",
    "import wandb\n",
    "api_key = 'e39350c7003ab06462caad3dd36b7f6a14bf8670'\n",
    "!wandb login e39350c7003ab06462caad3dd36b7f6a14bf8670\n",
    "from transformers import EvalPrediction\n",
    "from transformers import BertTokenizer, BertForTokenClassification, Trainer, TrainingArguments\n",
    "from datasets import load_dataset\n",
    "import evaluate\n",
    "from tqdm import tqdm\n",
    "import torch \n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transforming Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T05:25:20.163853Z",
     "iopub.status.busy": "2024-04-23T05:25:20.163193Z",
     "iopub.status.idle": "2024-04-23T05:25:20.174588Z",
     "shell.execute_reply": "2024-04-23T05:25:20.173729Z",
     "shell.execute_reply.started": "2024-04-23T05:25:20.163821Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_df(file_path, start_index):\n",
    "    with open(file_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    # Initialize lists to store data\n",
    "    topics = []\n",
    "    abstracts = []\n",
    "    texts = []\n",
    "    entities_list = []\n",
    "    classes_list = []\n",
    "\n",
    "    # Iterate through the lines of the file\n",
    "    i = start_index\n",
    "    while i < len(lines):\n",
    "        # Extract topic\n",
    "    #     topic_match = re.match(r'^(\\d+\\|t\\|.*)\\n$', lines[i])\n",
    "        topic_match = re.match(r'^\\d+\\|t\\|(.*)\\n$', lines[i])\n",
    "        if topic_match:\n",
    "            topic = topic_match.group(1)\n",
    "            i += 1\n",
    "        else:\n",
    "            break  # Break if no valid topic found\n",
    "\n",
    "        # Extract abstract\n",
    "    #     abstract_match = re.match(r'^(\\d+\\|a\\|.*)\\n$', lines[i])\n",
    "        abstract_match = re.match(r'^\\d+\\|a\\|(.*)\\n$', lines[i])\n",
    "        if abstract_match:\n",
    "            abstract = abstract_match.group(1)\n",
    "            i += 1\n",
    "        else:\n",
    "            break  # Break if no valid abstract found\n",
    "\n",
    "        text = topic + \" \" + abstract\n",
    "        # Initialize lists to store entities and classes for this instance\n",
    "        entities = []\n",
    "        classes = []\n",
    "\n",
    "        # Extract entities and classes\n",
    "        while i < len(lines) and lines[i] != \"\\n\":\n",
    "            entity_match = re.match(r'^(\\d+)\\t(\\d+)\\t(\\d+)\\t([^\\t]+)\\t([^\\t]+)\\t([^\\n]+)\\n$', lines[i])\n",
    "            if entity_match:\n",
    "                entities.append(entity_match.group(4))\n",
    "                classes.append(entity_match.group(5))\n",
    "                i += 1\n",
    "            else:\n",
    "                break  # Break if no valid entity found\n",
    "\n",
    "        # Store data for this instance\n",
    "        topics.append(topic)\n",
    "        abstracts.append(abstract)\n",
    "        texts.append(text)\n",
    "        entities_list.append(entities)\n",
    "        classes_list.append(classes)\n",
    "\n",
    "        # Skip the empty line\n",
    "        i += 1\n",
    "\n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'Topic': topics,\n",
    "        'Abstract': abstracts,\n",
    "        'Text': texts,\n",
    "        'Entities': entities_list,\n",
    "        'Classes': classes_list\n",
    "    })\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T05:25:20.175813Z",
     "iopub.status.busy": "2024-04-23T05:25:20.175578Z",
     "iopub.status.idle": "2024-04-23T05:25:20.288006Z",
     "shell.execute_reply": "2024-04-23T05:25:20.287307Z",
     "shell.execute_reply.started": "2024-04-23T05:25:20.175792Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df = create_df(\"NCBItrainset_corpus.txt\", 1)\n",
    "dev_df = create_df(\"NCBIdevelopset_corpus.txt\", 1)\n",
    "test_df = create_df(\"NCBItestset_corpus.txt\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T05:25:20.289988Z",
     "iopub.status.busy": "2024-04-23T05:25:20.289718Z",
     "iopub.status.idle": "2024-04-23T05:25:20.312700Z",
     "shell.execute_reply": "2024-04-23T05:25:20.311850Z",
     "shell.execute_reply.started": "2024-04-23T05:25:20.289965Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Text</th>\n",
       "      <th>Entities</th>\n",
       "      <th>Classes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A common human skin tumour is caused by activa...</td>\n",
       "      <td>WNT signalling orchestrates a number of develo...</td>\n",
       "      <td>A common human skin tumour is caused by activa...</td>\n",
       "      <td>[skin tumour, cancer, colon cancers, adenomato...</td>\n",
       "      <td>[DiseaseClass, DiseaseClass, DiseaseClass, Spe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HFE mutations analysis in 711 hemochromatosis ...</td>\n",
       "      <td>Hereditary hemochromatosis (HH) is a common au...</td>\n",
       "      <td>HFE mutations analysis in 711 hemochromatosis ...</td>\n",
       "      <td>[hemochromatosis, hemochromatosis, Hereditary ...</td>\n",
       "      <td>[Modifier, SpecificDisease, SpecificDisease, S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Germline BRCA1 alterations in a population-bas...</td>\n",
       "      <td>The objective of this study was to provide mor...</td>\n",
       "      <td>Germline BRCA1 alterations in a population-bas...</td>\n",
       "      <td>[ovarian cancer, breast cancer, ovarian cancer...</td>\n",
       "      <td>[Modifier, Modifier, Modifier, Modifier, Modif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Identification of APC2, a homologue of the ade...</td>\n",
       "      <td>The adenomatous polyposis coli (APC) tumour-su...</td>\n",
       "      <td>Identification of APC2, a homologue of the ade...</td>\n",
       "      <td>[adenomatous polyposis coli tumour, adenomatou...</td>\n",
       "      <td>[Modifier, Modifier, Modifier, Modifier, Speci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Familial deficiency of the seventh component o...</td>\n",
       "      <td>The serum of a 29-year old woman with a recent...</td>\n",
       "      <td>Familial deficiency of the seventh component o...</td>\n",
       "      <td>[Familial deficiency of the seventh component ...</td>\n",
       "      <td>[SpecificDisease, DiseaseClass, SpecificDiseas...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Topic  \\\n",
       "0  A common human skin tumour is caused by activa...   \n",
       "1  HFE mutations analysis in 711 hemochromatosis ...   \n",
       "2  Germline BRCA1 alterations in a population-bas...   \n",
       "3  Identification of APC2, a homologue of the ade...   \n",
       "4  Familial deficiency of the seventh component o...   \n",
       "\n",
       "                                            Abstract  \\\n",
       "0  WNT signalling orchestrates a number of develo...   \n",
       "1  Hereditary hemochromatosis (HH) is a common au...   \n",
       "2  The objective of this study was to provide mor...   \n",
       "3  The adenomatous polyposis coli (APC) tumour-su...   \n",
       "4  The serum of a 29-year old woman with a recent...   \n",
       "\n",
       "                                                Text  \\\n",
       "0  A common human skin tumour is caused by activa...   \n",
       "1  HFE mutations analysis in 711 hemochromatosis ...   \n",
       "2  Germline BRCA1 alterations in a population-bas...   \n",
       "3  Identification of APC2, a homologue of the ade...   \n",
       "4  Familial deficiency of the seventh component o...   \n",
       "\n",
       "                                            Entities  \\\n",
       "0  [skin tumour, cancer, colon cancers, adenomato...   \n",
       "1  [hemochromatosis, hemochromatosis, Hereditary ...   \n",
       "2  [ovarian cancer, breast cancer, ovarian cancer...   \n",
       "3  [adenomatous polyposis coli tumour, adenomatou...   \n",
       "4  [Familial deficiency of the seventh component ...   \n",
       "\n",
       "                                             Classes  \n",
       "0  [DiseaseClass, DiseaseClass, DiseaseClass, Spe...  \n",
       "1  [Modifier, SpecificDisease, SpecificDisease, S...  \n",
       "2  [Modifier, Modifier, Modifier, Modifier, Modif...  \n",
       "3  [Modifier, Modifier, Modifier, Modifier, Speci...  \n",
       "4  [SpecificDisease, DiseaseClass, SpecificDiseas...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T05:25:20.313857Z",
     "iopub.status.busy": "2024-04-23T05:25:20.313598Z",
     "iopub.status.idle": "2024-04-23T05:25:20.328130Z",
     "shell.execute_reply": "2024-04-23T05:25:20.327172Z",
     "shell.execute_reply.started": "2024-04-23T05:25:20.313835Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Text</th>\n",
       "      <th>Entities</th>\n",
       "      <th>Classes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Somatic-cell selection is a major determinant ...</td>\n",
       "      <td>X-chromosome inactivation in mammals is regard...</td>\n",
       "      <td>Somatic-cell selection is a major determinant ...</td>\n",
       "      <td>[enzyme deficiency, glucose-6-phosphate dehydr...</td>\n",
       "      <td>[DiseaseClass, SpecificDisease, SpecificDiseas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The ataxia-telangiectasia gene product, a cons...</td>\n",
       "      <td>The product of the ataxia-telangiectasia gene ...</td>\n",
       "      <td>The ataxia-telangiectasia gene product, a cons...</td>\n",
       "      <td>[ataxia-telangiectasia, ataxia-telangiectasia,...</td>\n",
       "      <td>[Modifier, Modifier, Modifier]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Molecular basis for Duarte and Los Angeles var...</td>\n",
       "      <td>Human orythrocytes that are homozygous for the...</td>\n",
       "      <td>Molecular basis for Duarte and Los Angeles var...</td>\n",
       "      <td>[Duarte and Los Angeles variant galactosemia, ...</td>\n",
       "      <td>[CompositeMention, SpecificDisease, SpecificDi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>An intronic mutation in a lariat branchpoint s...</td>\n",
       "      <td>The first step in the splicing of an intron fr...</td>\n",
       "      <td>An intronic mutation in a lariat branchpoint s...</td>\n",
       "      <td>[inherited human disorder, fish-eye disease, f...</td>\n",
       "      <td>[DiseaseClass, SpecificDisease, SpecificDiseas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Genetic heterogeneity in hereditary breast can...</td>\n",
       "      <td>The common hereditary forms of breast cancer h...</td>\n",
       "      <td>Genetic heterogeneity in hereditary breast can...</td>\n",
       "      <td>[hereditary breast cancer, breast cancer, here...</td>\n",
       "      <td>[SpecificDisease, SpecificDisease, SpecificDis...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Topic  \\\n",
       "0  Somatic-cell selection is a major determinant ...   \n",
       "1  The ataxia-telangiectasia gene product, a cons...   \n",
       "2  Molecular basis for Duarte and Los Angeles var...   \n",
       "3  An intronic mutation in a lariat branchpoint s...   \n",
       "4  Genetic heterogeneity in hereditary breast can...   \n",
       "\n",
       "                                            Abstract  \\\n",
       "0  X-chromosome inactivation in mammals is regard...   \n",
       "1  The product of the ataxia-telangiectasia gene ...   \n",
       "2  Human orythrocytes that are homozygous for the...   \n",
       "3  The first step in the splicing of an intron fr...   \n",
       "4  The common hereditary forms of breast cancer h...   \n",
       "\n",
       "                                                Text  \\\n",
       "0  Somatic-cell selection is a major determinant ...   \n",
       "1  The ataxia-telangiectasia gene product, a cons...   \n",
       "2  Molecular basis for Duarte and Los Angeles var...   \n",
       "3  An intronic mutation in a lariat branchpoint s...   \n",
       "4  Genetic heterogeneity in hereditary breast can...   \n",
       "\n",
       "                                            Entities  \\\n",
       "0  [enzyme deficiency, glucose-6-phosphate dehydr...   \n",
       "1  [ataxia-telangiectasia, ataxia-telangiectasia,...   \n",
       "2  [Duarte and Los Angeles variant galactosemia, ...   \n",
       "3  [inherited human disorder, fish-eye disease, f...   \n",
       "4  [hereditary breast cancer, breast cancer, here...   \n",
       "\n",
       "                                             Classes  \n",
       "0  [DiseaseClass, SpecificDisease, SpecificDiseas...  \n",
       "1                     [Modifier, Modifier, Modifier]  \n",
       "2  [CompositeMention, SpecificDisease, SpecificDi...  \n",
       "3  [DiseaseClass, SpecificDisease, SpecificDiseas...  \n",
       "4  [SpecificDisease, SpecificDisease, SpecificDis...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T05:25:20.329382Z",
     "iopub.status.busy": "2024-04-23T05:25:20.329123Z",
     "iopub.status.idle": "2024-04-23T05:25:20.348190Z",
     "shell.execute_reply": "2024-04-23T05:25:20.347261Z",
     "shell.execute_reply.started": "2024-04-23T05:25:20.329361Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Text</th>\n",
       "      <th>Entities</th>\n",
       "      <th>Classes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Genetic mapping of the copper toxicosis locus ...</td>\n",
       "      <td>Abnormal hepatic copper accumulation is recogn...</td>\n",
       "      <td>Genetic mapping of the copper toxicosis locus ...</td>\n",
       "      <td>[copper toxicosis, hepatic copper accumulation...</td>\n",
       "      <td>[Modifier, SpecificDisease, DiseaseClass, Spec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Molecular analysis of the APC gene in 205 fami...</td>\n",
       "      <td>BACKGROUND/AIMS  The development of colorectal...</td>\n",
       "      <td>Molecular analysis of the APC gene in 205 fami...</td>\n",
       "      <td>[APC, FAP, APC, colorectal cancer, colorectal ...</td>\n",
       "      <td>[Modifier, SpecificDisease, Modifier, Modifier...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A European multicenter study of phenylalanine ...</td>\n",
       "      <td>Phenylketonuria (PKU) and mild hyperphenylalan...</td>\n",
       "      <td>A European multicenter study of phenylalanine ...</td>\n",
       "      <td>[phenylalanine hydroxylase deficiency, Phenylk...</td>\n",
       "      <td>[SpecificDisease, SpecificDisease, SpecificDis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Disruption of splicing regulated by a CUG-bind...</td>\n",
       "      <td>Myotonic dystrophy (DM) is caused by a CTG exp...</td>\n",
       "      <td>Disruption of splicing regulated by a CUG-bind...</td>\n",
       "      <td>[myotonic dystrophy, Myotonic dystrophy, DM, D...</td>\n",
       "      <td>[SpecificDisease, SpecificDisease, SpecificDis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Maternal disomy and Prader-Willi syndrome cons...</td>\n",
       "      <td>Maternal uniparental disomy (UPD) for chromoso...</td>\n",
       "      <td>Maternal disomy and Prader-Willi syndrome cons...</td>\n",
       "      <td>[Maternal disomy, Prader-Willi syndrome, Mater...</td>\n",
       "      <td>[DiseaseClass, SpecificDisease, SpecificDiseas...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Topic  \\\n",
       "0  Genetic mapping of the copper toxicosis locus ...   \n",
       "1  Molecular analysis of the APC gene in 205 fami...   \n",
       "2  A European multicenter study of phenylalanine ...   \n",
       "3  Disruption of splicing regulated by a CUG-bind...   \n",
       "4  Maternal disomy and Prader-Willi syndrome cons...   \n",
       "\n",
       "                                            Abstract  \\\n",
       "0  Abnormal hepatic copper accumulation is recogn...   \n",
       "1  BACKGROUND/AIMS  The development of colorectal...   \n",
       "2  Phenylketonuria (PKU) and mild hyperphenylalan...   \n",
       "3  Myotonic dystrophy (DM) is caused by a CTG exp...   \n",
       "4  Maternal uniparental disomy (UPD) for chromoso...   \n",
       "\n",
       "                                                Text  \\\n",
       "0  Genetic mapping of the copper toxicosis locus ...   \n",
       "1  Molecular analysis of the APC gene in 205 fami...   \n",
       "2  A European multicenter study of phenylalanine ...   \n",
       "3  Disruption of splicing regulated by a CUG-bind...   \n",
       "4  Maternal disomy and Prader-Willi syndrome cons...   \n",
       "\n",
       "                                            Entities  \\\n",
       "0  [copper toxicosis, hepatic copper accumulation...   \n",
       "1  [APC, FAP, APC, colorectal cancer, colorectal ...   \n",
       "2  [phenylalanine hydroxylase deficiency, Phenylk...   \n",
       "3  [myotonic dystrophy, Myotonic dystrophy, DM, D...   \n",
       "4  [Maternal disomy, Prader-Willi syndrome, Mater...   \n",
       "\n",
       "                                             Classes  \n",
       "0  [Modifier, SpecificDisease, DiseaseClass, Spec...  \n",
       "1  [Modifier, SpecificDisease, Modifier, Modifier...  \n",
       "2  [SpecificDisease, SpecificDisease, SpecificDis...  \n",
       "3  [SpecificDisease, SpecificDisease, SpecificDis...  \n",
       "4  [DiseaseClass, SpecificDisease, SpecificDiseas...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T05:25:20.349429Z",
     "iopub.status.busy": "2024-04-23T05:25:20.349180Z",
     "iopub.status.idle": "2024-04-23T05:25:20.357775Z",
     "shell.execute_reply": "2024-04-23T05:25:20.356864Z",
     "shell.execute_reply.started": "2024-04-23T05:25:20.349408Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # Tokenization and lemmatization using SpaCy, removing stop words\n",
    "    doc = nlp(text)\n",
    "    tokens = [token.text for token in doc if not token.is_stop and token.is_alpha]\n",
    "    lemmas = [token.lemma_ for token in doc if not token.is_stop and token.is_alpha]\n",
    "    return tokens, lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T05:25:20.359789Z",
     "iopub.status.busy": "2024-04-23T05:25:20.358978Z",
     "iopub.status.idle": "2024-04-23T05:25:50.861707Z",
     "shell.execute_reply": "2024-04-23T05:25:50.860566Z",
     "shell.execute_reply.started": "2024-04-23T05:25:20.359764Z"
    }
   },
   "outputs": [],
   "source": [
    "# Apply preprocessing to Abstract column for train_df\n",
    "train_df[['Text_Tokens', 'Text_Lemmas']] = train_df['Text'].apply(lambda x: pd.Series(preprocess_text(x)))\n",
    "\n",
    "# Apply preprocessing to Abstract column for dev_df\n",
    "dev_df[['Text_Tokens', 'Text_Lemmas']] = dev_df['Text'].apply(lambda x: pd.Series(preprocess_text(x)))\n",
    "\n",
    "# Apply preprocessing to Abstract column for test_df\n",
    "test_df[['Text_Tokens', 'Text_Lemmas']] = test_df['Text'].apply(lambda x: pd.Series(preprocess_text(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T05:25:50.863836Z",
     "iopub.status.busy": "2024-04-23T05:25:50.863401Z",
     "iopub.status.idle": "2024-04-23T05:25:50.895845Z",
     "shell.execute_reply": "2024-04-23T05:25:50.894914Z",
     "shell.execute_reply.started": "2024-04-23T05:25:50.863800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Text</th>\n",
       "      <th>Entities</th>\n",
       "      <th>Classes</th>\n",
       "      <th>Text_Tokens</th>\n",
       "      <th>Text_Lemmas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Somatic-cell selection is a major determinant ...</td>\n",
       "      <td>X-chromosome inactivation in mammals is regard...</td>\n",
       "      <td>Somatic-cell selection is a major determinant ...</td>\n",
       "      <td>[enzyme deficiency, glucose-6-phosphate dehydr...</td>\n",
       "      <td>[DiseaseClass, SpecificDisease, SpecificDiseas...</td>\n",
       "      <td>[Somatic, cell, selection, major, determinant,...</td>\n",
       "      <td>[somatic, cell, selection, major, determinant,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The ataxia-telangiectasia gene product, a cons...</td>\n",
       "      <td>The product of the ataxia-telangiectasia gene ...</td>\n",
       "      <td>The ataxia-telangiectasia gene product, a cons...</td>\n",
       "      <td>[ataxia-telangiectasia, ataxia-telangiectasia,...</td>\n",
       "      <td>[Modifier, Modifier, Modifier]</td>\n",
       "      <td>[ataxia, telangiectasia, gene, product, consti...</td>\n",
       "      <td>[ataxia, telangiectasia, gene, product, consti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Molecular basis for Duarte and Los Angeles var...</td>\n",
       "      <td>Human orythrocytes that are homozygous for the...</td>\n",
       "      <td>Molecular basis for Duarte and Los Angeles var...</td>\n",
       "      <td>[Duarte and Los Angeles variant galactosemia, ...</td>\n",
       "      <td>[CompositeMention, SpecificDisease, SpecificDi...</td>\n",
       "      <td>[Molecular, basis, Duarte, Los, Angeles, varia...</td>\n",
       "      <td>[molecular, basis, Duarte, Los, Angeles, varia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>An intronic mutation in a lariat branchpoint s...</td>\n",
       "      <td>The first step in the splicing of an intron fr...</td>\n",
       "      <td>An intronic mutation in a lariat branchpoint s...</td>\n",
       "      <td>[inherited human disorder, fish-eye disease, f...</td>\n",
       "      <td>[DiseaseClass, SpecificDisease, SpecificDiseas...</td>\n",
       "      <td>[intronic, mutation, lariat, branchpoint, sequ...</td>\n",
       "      <td>[intronic, mutation, lariat, branchpoint, sequ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Genetic heterogeneity in hereditary breast can...</td>\n",
       "      <td>The common hereditary forms of breast cancer h...</td>\n",
       "      <td>Genetic heterogeneity in hereditary breast can...</td>\n",
       "      <td>[hereditary breast cancer, breast cancer, here...</td>\n",
       "      <td>[SpecificDisease, SpecificDisease, SpecificDis...</td>\n",
       "      <td>[Genetic, heterogeneity, hereditary, breast, c...</td>\n",
       "      <td>[genetic, heterogeneity, hereditary, breast, c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Topic  \\\n",
       "0  Somatic-cell selection is a major determinant ...   \n",
       "1  The ataxia-telangiectasia gene product, a cons...   \n",
       "2  Molecular basis for Duarte and Los Angeles var...   \n",
       "3  An intronic mutation in a lariat branchpoint s...   \n",
       "4  Genetic heterogeneity in hereditary breast can...   \n",
       "\n",
       "                                            Abstract  \\\n",
       "0  X-chromosome inactivation in mammals is regard...   \n",
       "1  The product of the ataxia-telangiectasia gene ...   \n",
       "2  Human orythrocytes that are homozygous for the...   \n",
       "3  The first step in the splicing of an intron fr...   \n",
       "4  The common hereditary forms of breast cancer h...   \n",
       "\n",
       "                                                Text  \\\n",
       "0  Somatic-cell selection is a major determinant ...   \n",
       "1  The ataxia-telangiectasia gene product, a cons...   \n",
       "2  Molecular basis for Duarte and Los Angeles var...   \n",
       "3  An intronic mutation in a lariat branchpoint s...   \n",
       "4  Genetic heterogeneity in hereditary breast can...   \n",
       "\n",
       "                                            Entities  \\\n",
       "0  [enzyme deficiency, glucose-6-phosphate dehydr...   \n",
       "1  [ataxia-telangiectasia, ataxia-telangiectasia,...   \n",
       "2  [Duarte and Los Angeles variant galactosemia, ...   \n",
       "3  [inherited human disorder, fish-eye disease, f...   \n",
       "4  [hereditary breast cancer, breast cancer, here...   \n",
       "\n",
       "                                             Classes  \\\n",
       "0  [DiseaseClass, SpecificDisease, SpecificDiseas...   \n",
       "1                     [Modifier, Modifier, Modifier]   \n",
       "2  [CompositeMention, SpecificDisease, SpecificDi...   \n",
       "3  [DiseaseClass, SpecificDisease, SpecificDiseas...   \n",
       "4  [SpecificDisease, SpecificDisease, SpecificDis...   \n",
       "\n",
       "                                         Text_Tokens  \\\n",
       "0  [Somatic, cell, selection, major, determinant,...   \n",
       "1  [ataxia, telangiectasia, gene, product, consti...   \n",
       "2  [Molecular, basis, Duarte, Los, Angeles, varia...   \n",
       "3  [intronic, mutation, lariat, branchpoint, sequ...   \n",
       "4  [Genetic, heterogeneity, hereditary, breast, c...   \n",
       "\n",
       "                                         Text_Lemmas  \n",
       "0  [somatic, cell, selection, major, determinant,...  \n",
       "1  [ataxia, telangiectasia, gene, product, consti...  \n",
       "2  [molecular, basis, Duarte, Los, Angeles, varia...  \n",
       "3  [intronic, mutation, lariat, branchpoint, sequ...  \n",
       "4  [genetic, heterogeneity, hereditary, breast, c...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BIO Notation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_specific_disease_entities(row):\n",
    "    return [entity for entity, class_ in zip(row['Entities'], row['Classes']) if class_ == \"SpecificDisease\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['SpecificDiseaseEntities'] = train_df.apply(get_specific_disease_entities, axis=1)\n",
    "dev_df['SpecificDiseaseEntities'] = dev_df.apply(get_specific_disease_entities, axis=1)\n",
    "test_df['SpecificDiseaseEntities'] = test_df.apply(get_specific_disease_entities, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# id2label = {\n",
    "#     0: \"O\",\n",
    "#     1: \"B\",\n",
    "#     2: \"I\",\n",
    "# }\n",
    "\n",
    "def generate_bio_ner(row):\n",
    "    ner_list = []\n",
    "    specific_disease_entities = row['SpecificDiseaseEntities']\n",
    "    for token in row['Text_Tokens']:\n",
    "        matching_entities = [entity for entity in specific_disease_entities if token in entity.split()]\n",
    "        if matching_entities:\n",
    "            entity = matching_entities[0]\n",
    "            if token == entity.split()[0]:\n",
    "                ner_list.append(1)\n",
    "            else:\n",
    "                ner_list.append(2)\n",
    "        else:\n",
    "            ner_list.append(0)\n",
    "    return ner_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['ner_tags'] = train_df.apply(generate_bio_ner, axis=1)\n",
    "dev_df['ner_tags'] = dev_df.apply(generate_bio_ner, axis=1)\n",
    "test_df['ner_tags'] = test_df.apply(generate_bio_ner, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T05:25:50.900569Z",
     "iopub.status.busy": "2024-04-23T05:25:50.900254Z",
     "iopub.status.idle": "2024-04-23T05:25:50.925684Z",
     "shell.execute_reply": "2024-04-23T05:25:50.924778Z",
     "shell.execute_reply.started": "2024-04-23T05:25:50.900543Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Instances</th>\n",
       "      <th>Average Text Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Train</td>\n",
       "      <td>593</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dev</td>\n",
       "      <td>100</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Test</td>\n",
       "      <td>100</td>\n",
       "      <td>204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Dataset  Instances  Average Text Length\n",
       "0   Train        593                  190\n",
       "1     Dev        100                  201\n",
       "2    Test        100                  204"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate statistics for train_df\n",
    "train_stats = {\n",
    "    'Dataset': 'Train',\n",
    "    'Instances': len(train_df),\n",
    "    'Average Text Length': int(train_df['Text'].apply(lambda x: len(x.split())).mean())\n",
    "}\n",
    "\n",
    "# Calculate statistics for dev_df\n",
    "dev_stats = {\n",
    "    'Dataset': 'Dev',\n",
    "    'Instances': len(dev_df),\n",
    "    'Average Text Length': int(dev_df['Text'].apply(lambda x: len(x.split())).mean())\n",
    "}\n",
    "\n",
    "# Calculate statistics for test_df\n",
    "test_stats = {\n",
    "    'Dataset': 'Test',\n",
    "    'Instances': len(test_df),\n",
    "    'Average Text Length': int(test_df['Text'].apply(lambda x: len(x.split())).mean())\n",
    "}\n",
    "\n",
    "# Combine statistics into a DataFrame\n",
    "pd.DataFrame([train_stats, dev_stats, test_stats])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T05:25:50.927090Z",
     "iopub.status.busy": "2024-04-23T05:25:50.926808Z",
     "iopub.status.idle": "2024-04-23T05:25:50.957175Z",
     "shell.execute_reply": "2024-04-23T05:25:50.956246Z",
     "shell.execute_reply.started": "2024-04-23T05:25:50.927067Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train</th>\n",
       "      <th>Dev</th>\n",
       "      <th>Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SpecificDisease</th>\n",
       "      <td>2972</td>\n",
       "      <td>412</td>\n",
       "      <td>555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Modifier</th>\n",
       "      <td>1289</td>\n",
       "      <td>214</td>\n",
       "      <td>264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DiseaseClass</th>\n",
       "      <td>769</td>\n",
       "      <td>126</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CompositeMention</th>\n",
       "      <td>115</td>\n",
       "      <td>35</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Train  Dev  Test\n",
       "SpecificDisease    2972  412   555\n",
       "Modifier           1289  214   264\n",
       "DiseaseClass        769  126   121\n",
       "CompositeMention    115   35    20"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Value counts of each dataframe\n",
    "value_counts_df = pd.DataFrame({\n",
    "    'Train': train_df['Classes'].explode().value_counts(),\n",
    "    'Dev': dev_df['Classes'].explode().value_counts(),\n",
    "    'Test': test_df['Classes'].explode().value_counts()\n",
    "})\n",
    "\n",
    "value_counts_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baselines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entity Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline 1 - Random Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T05:25:50.958819Z",
     "iopub.status.busy": "2024-04-23T05:25:50.958442Z",
     "iopub.status.idle": "2024-04-23T05:25:50.966200Z",
     "shell.execute_reply": "2024-04-23T05:25:50.965155Z",
     "shell.execute_reply.started": "2024-04-23T05:25:50.958786Z"
    }
   },
   "outputs": [],
   "source": [
    "def baseline_entity_extraction(text):\n",
    "    # Randomly decide the length of entities (in words)\n",
    "    entity_length = random.randint(1, 3)\n",
    "    \n",
    "    # Randomly decide how many entities to extract\n",
    "    num_entities = random.randint(1, 5)\n",
    "    \n",
    "    # Extract entities based on random decisions\n",
    "    entities = []\n",
    "    for _ in range(num_entities):\n",
    "        start_idx = random.randint(0, len(text.split()) - entity_length)\n",
    "        end_idx = start_idx + entity_length\n",
    "        entity = \" \".join(text.split()[start_idx:end_idx])\n",
    "        if len(entity) > 0:\n",
    "            entities.append(entity)\n",
    "    \n",
    "    return entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T05:25:50.968298Z",
     "iopub.status.busy": "2024-04-23T05:25:50.967975Z",
     "iopub.status.idle": "2024-04-23T05:25:50.984735Z",
     "shell.execute_reply": "2024-04-23T05:25:50.983945Z",
     "shell.execute_reply.started": "2024-04-23T05:25:50.968272Z"
    }
   },
   "outputs": [],
   "source": [
    "# Apply baseline entity extraction to test_df\n",
    "test_df['Baseline_1_Entities'] = test_df['Text'].apply(baseline_entity_extraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T05:25:50.985964Z",
     "iopub.status.busy": "2024-04-23T05:25:50.985691Z",
     "iopub.status.idle": "2024-04-23T05:25:50.995508Z",
     "shell.execute_reply": "2024-04-23T05:25:50.994676Z",
     "shell.execute_reply.started": "2024-04-23T05:25:50.985942Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to compute precision, recall, and F1 score\n",
    "def evaluate_baseline(true_entities, predicted_entities):\n",
    "    true_entities = set(true_entities)\n",
    "    predicted_entities = set(predicted_entities)\n",
    "    \n",
    "    # Calculate precision, recall, and F1 score\n",
    "    precision = len(true_entities.intersection(predicted_entities)) / len(predicted_entities)\n",
    "    recall = len(true_entities.intersection(predicted_entities)) / len(true_entities)\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if precision + recall > 0 else 0\n",
    "    \n",
    "    return precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T05:25:50.996773Z",
     "iopub.status.busy": "2024-04-23T05:25:50.996537Z",
     "iopub.status.idle": "2024-04-23T05:25:51.007731Z",
     "shell.execute_reply": "2024-04-23T05:25:51.006879Z",
     "shell.execute_reply.started": "2024-04-23T05:25:50.996752Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline 1 Evaluation Results:\n",
      "Average Precision: 0.002\n",
      "Average Recall: 0.003\n",
      "Average F1 Score: 0.002\n"
     ]
    }
   ],
   "source": [
    "# Compute precision, recall, and F1 score for baseline\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "f1_scores = []\n",
    "\n",
    "for true_entities, predicted_entities in zip(test_df['Entities'], test_df['Baseline_1_Entities']):\n",
    "    precision, recall, f1 = evaluate_baseline(true_entities, predicted_entities)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "# Calculate average scores\n",
    "average_precision = sum(precision_scores) / len(precision_scores)\n",
    "average_recall = sum(recall_scores) / len(recall_scores)\n",
    "average_f1 = sum(f1_scores) / len(f1_scores)\n",
    "\n",
    "print(\"Baseline 1 Evaluation Results:\")\n",
    "print(f\"Average Precision: {average_precision:.3f}\")\n",
    "print(f\"Average Recall: {average_recall:.3f}\")\n",
    "print(f\"Average F1 Score: {average_f1:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline 2 - Most Frequent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T05:25:51.009034Z",
     "iopub.status.busy": "2024-04-23T05:25:51.008786Z",
     "iopub.status.idle": "2024-04-23T05:25:51.027975Z",
     "shell.execute_reply": "2024-04-23T05:25:51.027128Z",
     "shell.execute_reply.started": "2024-04-23T05:25:51.009012Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Calculate the most frequent length of entities in the dataset\n",
    "all_entities = train_df['Entities'].explode()\n",
    "entity_lengths = [len(entity.split()) for entity in all_entities]\n",
    "most_frequent_length = Counter(entity_lengths).most_common(1)[0][0]\n",
    "\n",
    "def baseline_entity_extraction_most_frequent(text, most_frequent_length):\n",
    "    # Determine the number of entities to extract\n",
    "    num_entities = random.randint(1, 3)  # You can adjust the range as needed\n",
    "    \n",
    "    # Extract entities with the most frequent length\n",
    "    entities = []\n",
    "    for _ in range(num_entities):\n",
    "        start_idx = random.randint(0, len(text.split()) - most_frequent_length)\n",
    "        end_idx = start_idx + most_frequent_length\n",
    "        entity = \" \".join(text.split()[start_idx:end_idx])\n",
    "        if len(entity) > 0:\n",
    "            entities.append(entity)\n",
    "    \n",
    "    return entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T05:25:51.029274Z",
     "iopub.status.busy": "2024-04-23T05:25:51.028954Z",
     "iopub.status.idle": "2024-04-23T05:25:51.048783Z",
     "shell.execute_reply": "2024-04-23T05:25:51.047784Z",
     "shell.execute_reply.started": "2024-04-23T05:25:51.029245Z"
    }
   },
   "outputs": [],
   "source": [
    "# Apply baseline entity extraction to test_df using the most frequent length\n",
    "test_df['Baseline_2_Entities'] = test_df['Text'].apply(lambda x: baseline_entity_extraction_most_frequent(x, most_frequent_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T05:25:51.053340Z",
     "iopub.status.busy": "2024-04-23T05:25:51.052997Z",
     "iopub.status.idle": "2024-04-23T05:25:51.068376Z",
     "shell.execute_reply": "2024-04-23T05:25:51.067142Z",
     "shell.execute_reply.started": "2024-04-23T05:25:51.053298Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline 2 Evaluation Results:\n",
      "Average Precision: 0.020\n",
      "Average Recall: 0.004\n",
      "Average F1 Score: 0.006\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Baseline 2\n",
    "precision_scores_most_frequent = []\n",
    "recall_scores_most_frequent = []\n",
    "f1_scores_most_frequent = []\n",
    "\n",
    "for true_entities, predicted_entities in zip(test_df['Entities'], test_df['Baseline_2_Entities']):\n",
    "    precision, recall, f1 = evaluate_baseline(true_entities, predicted_entities)\n",
    "    precision_scores_most_frequent.append(precision)\n",
    "    recall_scores_most_frequent.append(recall)\n",
    "    f1_scores_most_frequent.append(f1)\n",
    "\n",
    "# Calculate average scores for Baseline 2\n",
    "average_precision_most_frequent = sum(precision_scores_most_frequent) / len(precision_scores_most_frequent)\n",
    "average_recall_most_frequent = sum(recall_scores_most_frequent) / len(recall_scores_most_frequent)\n",
    "average_f1_most_frequent = sum(f1_scores_most_frequent) / len(f1_scores_most_frequent)\n",
    "\n",
    "print(\"Baseline 2 Evaluation Results:\")\n",
    "print(f\"Average Precision: {average_precision_most_frequent:.3f}\")\n",
    "print(f\"Average Recall: {average_recall_most_frequent:.3f}\")\n",
    "print(f\"Average F1 Score: {average_f1_most_frequent:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T05:25:51.072658Z",
     "iopub.status.busy": "2024-04-23T05:25:51.072319Z",
     "iopub.status.idle": "2024-04-23T05:25:51.084291Z",
     "shell.execute_reply": "2024-04-23T05:25:51.083382Z",
     "shell.execute_reply.started": "2024-04-23T05:25:51.072630Z"
    }
   },
   "outputs": [],
   "source": [
    "def random_clustering(n_samples, n_clusters):\n",
    "    np.random.seed(630)\n",
    "    labels = np.random.randint(0, n_clusters, size=n_samples)\n",
    "    return labels\n",
    "\n",
    "def clustering_baseline(test_df, col1, col2):\n",
    "    specific_disease_entities = test_df.apply(lambda row: [entity for entity, class_ in zip(row[col1], row[col2]) if class_ == 'SpecificDisease'], axis=1)\n",
    "    unique_entities = set([entity for sublist in specific_disease_entities for entity in sublist])\n",
    "\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    X = vectorizer.fit_transform(unique_entities)\n",
    "\n",
    "    n_clusters = 5\n",
    "    n_samples = X.shape[0]\n",
    "    \n",
    "    random_labels = random_clustering(n_samples, n_clusters)\n",
    "    silhouette_avg = silhouette_score(X, random_labels)\n",
    "    return silhouette_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline 1 - Random Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T05:25:51.090692Z",
     "iopub.status.busy": "2024-04-23T05:25:51.088575Z",
     "iopub.status.idle": "2024-04-23T05:25:51.097960Z",
     "shell.execute_reply": "2024-04-23T05:25:51.096934Z",
     "shell.execute_reply.started": "2024-04-23T05:25:51.090667Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to randomly assign classes to entities\n",
    "def baseline_class_assignment(entities):\n",
    "    # Randomly generate classes for each entity\n",
    "    np.random.seed(630)\n",
    "    random_classes = [random.choice(['DiseaseClass', 'SpecificDisease', 'Modifier', 'CompositeMention']) for _ in entities]\n",
    "    return random_classes\n",
    "\n",
    "# Apply baseline class assignment to test_df\n",
    "test_df['Baseline_1_Classes'] = test_df['Baseline_1_Entities'].apply(baseline_class_assignment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T05:25:51.099648Z",
     "iopub.status.busy": "2024-04-23T05:25:51.099107Z",
     "iopub.status.idle": "2024-04-23T05:25:51.136450Z",
     "shell.execute_reply": "2024-04-23T05:25:51.135598Z",
     "shell.execute_reply.started": "2024-04-23T05:25:51.099616Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette Score for Baseline 1: -0.0159664500410288\n"
     ]
    }
   ],
   "source": [
    "baseline1_silhouette = clustering_baseline(test_df, 'Baseline_1_Entities', 'Baseline_1_Classes')\n",
    "print(f'Silhouette Score for Baseline 1: {baseline1_silhouette}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline 2 - Most Frequent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T05:25:51.138418Z",
     "iopub.status.busy": "2024-04-23T05:25:51.137677Z",
     "iopub.status.idle": "2024-04-23T05:25:51.146587Z",
     "shell.execute_reply": "2024-04-23T05:25:51.145653Z",
     "shell.execute_reply.started": "2024-04-23T05:25:51.138381Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate most frequent class from the training data\n",
    "most_frequent_class = train_df['Classes'].explode().value_counts().idxmax()\n",
    "\n",
    "# Function to assign most frequent class to entities\n",
    "def baseline_class_assignment_most_frequent(entities):\n",
    "    # Assign most frequent classes to each entity\n",
    "    return [most_frequent_class] * len(entities)\n",
    "\n",
    "# Apply baseline class assignment to test_df\n",
    "test_df['Baseline_2_Classes'] = test_df['Baseline_2_Entities'].apply(baseline_class_assignment_most_frequent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T05:25:51.148102Z",
     "iopub.status.busy": "2024-04-23T05:25:51.147809Z",
     "iopub.status.idle": "2024-04-23T05:25:51.166453Z",
     "shell.execute_reply": "2024-04-23T05:25:51.165658Z",
     "shell.execute_reply.started": "2024-04-23T05:25:51.148077Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette Score for Baseline 2: -0.01225949881011199\n"
     ]
    }
   ],
   "source": [
    "baseline2_silhouette = clustering_baseline(test_df, 'Baseline_2_Entities', 'Baseline_2_Classes')\n",
    "print(f'Silhouette Score for Baseline 2: {baseline2_silhouette}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T05:25:51.168184Z",
     "iopub.status.busy": "2024-04-23T05:25:51.167638Z",
     "iopub.status.idle": "2024-04-23T05:25:51.182683Z",
     "shell.execute_reply": "2024-04-23T05:25:51.181904Z",
     "shell.execute_reply.started": "2024-04-23T05:25:51.168154Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Baseline</th>\n",
       "      <th>Avg Precision</th>\n",
       "      <th>Avg Recall</th>\n",
       "      <th>Avg F1 Score</th>\n",
       "      <th>Silhouette Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline 1</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.002</td>\n",
       "      <td>-0.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Baseline 2</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.006</td>\n",
       "      <td>-0.012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Baseline  Avg Precision  Avg Recall  Avg F1 Score  Silhouette Score\n",
       "0  Baseline 1          0.002       0.003         0.002            -0.016\n",
       "1  Baseline 2          0.020       0.004         0.006            -0.012"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a DataFrame for evaluation results\n",
    "evaluation_results = pd.DataFrame({\n",
    "    'Baseline': ['Baseline 1', 'Baseline 2'],\n",
    "    'Avg Precision': [round(average_precision, 3), round(average_precision_most_frequent, 3)],\n",
    "    'Avg Recall': [round(average_recall, 3), round(average_recall_most_frequent, 3)],\n",
    "    'Avg F1 Score': [round(average_f1, 3), round(average_f1_most_frequent, 3)],\n",
    "    'Silhouette Score': [round(baseline1_silhouette, 3), round(baseline2_silhouette, 3)]\n",
    "})\n",
    "evaluation_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T05:25:51.184259Z",
     "iopub.status.busy": "2024-04-23T05:25:51.183910Z",
     "iopub.status.idle": "2024-04-23T05:25:51.197170Z",
     "shell.execute_reply": "2024-04-23T05:25:51.196326Z",
     "shell.execute_reply.started": "2024-04-23T05:25:51.184209Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Baseline</th>\n",
       "      <td>Baseline 1</td>\n",
       "      <td>Baseline 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Avg Precision</th>\n",
       "      <td>0.002</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Avg Recall</th>\n",
       "      <td>0.003</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Avg F1 Score</th>\n",
       "      <td>0.002</td>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Silhouette Score</th>\n",
       "      <td>-0.016</td>\n",
       "      <td>-0.012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           0           1\n",
       "Baseline          Baseline 1  Baseline 2\n",
       "Avg Precision          0.002        0.02\n",
       "Avg Recall             0.003       0.004\n",
       "Avg F1 Score           0.002       0.006\n",
       "Silhouette Score      -0.016      -0.012"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_results.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T05:25:51.198528Z",
     "iopub.status.busy": "2024-04-23T05:25:51.198235Z",
     "iopub.status.idle": "2024-04-23T05:25:51.213331Z",
     "shell.execute_reply": "2024-04-23T05:25:51.212616Z",
     "shell.execute_reply.started": "2024-04-23T05:25:51.198481Z"
    }
   },
   "outputs": [],
   "source": [
    "test_df.drop(columns = ['Baseline_1_Entities','Baseline_2_Entities'], inplace = True)\n",
    "test_df.drop(columns = ['Baseline_1_Classes','Baseline_2_Classes'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T05:25:51.257742Z",
     "iopub.status.busy": "2024-04-23T05:25:51.257477Z",
     "iopub.status.idle": "2024-04-23T05:25:51.283928Z",
     "shell.execute_reply": "2024-04-23T05:25:51.283110Z",
     "shell.execute_reply.started": "2024-04-23T05:25:51.257720Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, Trainer, TrainingArguments\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T05:25:51.285218Z",
     "iopub.status.busy": "2024-04-23T05:25:51.284903Z",
     "iopub.status.idle": "2024-04-23T05:25:51.295132Z",
     "shell.execute_reply": "2024-04-23T05:25:51.294233Z",
     "shell.execute_reply.started": "2024-04-23T05:25:51.285188Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1691"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df['Entities'].explode().unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T05:25:51.296453Z",
     "iopub.status.busy": "2024-04-23T05:25:51.296173Z",
     "iopub.status.idle": "2024-04-23T05:25:51.325014Z",
     "shell.execute_reply": "2024-04-23T05:25:51.324155Z",
     "shell.execute_reply.started": "2024-04-23T05:25:51.296430Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Text</th>\n",
       "      <th>Entities</th>\n",
       "      <th>Classes</th>\n",
       "      <th>Text_Tokens</th>\n",
       "      <th>Text_Lemmas</th>\n",
       "      <th>SpecificDiseaseEntities</th>\n",
       "      <th>ner_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A common human skin tumour is caused by activa...</td>\n",
       "      <td>WNT signalling orchestrates a number of develo...</td>\n",
       "      <td>A common human skin tumour is caused by activa...</td>\n",
       "      <td>[skin tumour, cancer, colon cancers, adenomato...</td>\n",
       "      <td>[DiseaseClass, DiseaseClass, DiseaseClass, Spe...</td>\n",
       "      <td>[common, human, skin, tumour, caused, activati...</td>\n",
       "      <td>[common, human, skin, tumour, cause, activate,...</td>\n",
       "      <td>[adenomatous polyposis coli, APC, pilomatricom...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HFE mutations analysis in 711 hemochromatosis ...</td>\n",
       "      <td>Hereditary hemochromatosis (HH) is a common au...</td>\n",
       "      <td>HFE mutations analysis in 711 hemochromatosis ...</td>\n",
       "      <td>[hemochromatosis, hemochromatosis, Hereditary ...</td>\n",
       "      <td>[Modifier, SpecificDisease, SpecificDisease, S...</td>\n",
       "      <td>[HFE, mutations, analysis, hemochromatosis, pr...</td>\n",
       "      <td>[HFE, mutation, analysis, hemochromatosis, pro...</td>\n",
       "      <td>[hemochromatosis, Hereditary hemochromatosis, ...</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Germline BRCA1 alterations in a population-bas...</td>\n",
       "      <td>The objective of this study was to provide mor...</td>\n",
       "      <td>Germline BRCA1 alterations in a population-bas...</td>\n",
       "      <td>[ovarian cancer, breast cancer, ovarian cancer...</td>\n",
       "      <td>[Modifier, Modifier, Modifier, Modifier, Modif...</td>\n",
       "      <td>[Germline, alterations, population, based, ser...</td>\n",
       "      <td>[Germline, alteration, population, base, serie...</td>\n",
       "      <td>[ovarian cancer]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Identification of APC2, a homologue of the ade...</td>\n",
       "      <td>The adenomatous polyposis coli (APC) tumour-su...</td>\n",
       "      <td>Identification of APC2, a homologue of the ade...</td>\n",
       "      <td>[adenomatous polyposis coli tumour, adenomatou...</td>\n",
       "      <td>[Modifier, Modifier, Modifier, Modifier, Speci...</td>\n",
       "      <td>[Identification, homologue, adenomatous, polyp...</td>\n",
       "      <td>[identification, homologue, adenomatous, polyp...</td>\n",
       "      <td>[cancer]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Familial deficiency of the seventh component o...</td>\n",
       "      <td>The serum of a 29-year old woman with a recent...</td>\n",
       "      <td>Familial deficiency of the seventh component o...</td>\n",
       "      <td>[Familial deficiency of the seventh component ...</td>\n",
       "      <td>[SpecificDisease, DiseaseClass, SpecificDiseas...</td>\n",
       "      <td>[Familial, deficiency, seventh, component, com...</td>\n",
       "      <td>[familial, deficiency, seventh, component, com...</td>\n",
       "      <td>[Familial deficiency of the seventh component ...</td>\n",
       "      <td>[1, 2, 2, 2, 2, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Topic  \\\n",
       "0  A common human skin tumour is caused by activa...   \n",
       "1  HFE mutations analysis in 711 hemochromatosis ...   \n",
       "2  Germline BRCA1 alterations in a population-bas...   \n",
       "3  Identification of APC2, a homologue of the ade...   \n",
       "4  Familial deficiency of the seventh component o...   \n",
       "\n",
       "                                            Abstract  \\\n",
       "0  WNT signalling orchestrates a number of develo...   \n",
       "1  Hereditary hemochromatosis (HH) is a common au...   \n",
       "2  The objective of this study was to provide mor...   \n",
       "3  The adenomatous polyposis coli (APC) tumour-su...   \n",
       "4  The serum of a 29-year old woman with a recent...   \n",
       "\n",
       "                                                Text  \\\n",
       "0  A common human skin tumour is caused by activa...   \n",
       "1  HFE mutations analysis in 711 hemochromatosis ...   \n",
       "2  Germline BRCA1 alterations in a population-bas...   \n",
       "3  Identification of APC2, a homologue of the ade...   \n",
       "4  Familial deficiency of the seventh component o...   \n",
       "\n",
       "                                            Entities  \\\n",
       "0  [skin tumour, cancer, colon cancers, adenomato...   \n",
       "1  [hemochromatosis, hemochromatosis, Hereditary ...   \n",
       "2  [ovarian cancer, breast cancer, ovarian cancer...   \n",
       "3  [adenomatous polyposis coli tumour, adenomatou...   \n",
       "4  [Familial deficiency of the seventh component ...   \n",
       "\n",
       "                                             Classes  \\\n",
       "0  [DiseaseClass, DiseaseClass, DiseaseClass, Spe...   \n",
       "1  [Modifier, SpecificDisease, SpecificDisease, S...   \n",
       "2  [Modifier, Modifier, Modifier, Modifier, Modif...   \n",
       "3  [Modifier, Modifier, Modifier, Modifier, Speci...   \n",
       "4  [SpecificDisease, DiseaseClass, SpecificDiseas...   \n",
       "\n",
       "                                         Text_Tokens  \\\n",
       "0  [common, human, skin, tumour, caused, activati...   \n",
       "1  [HFE, mutations, analysis, hemochromatosis, pr...   \n",
       "2  [Germline, alterations, population, based, ser...   \n",
       "3  [Identification, homologue, adenomatous, polyp...   \n",
       "4  [Familial, deficiency, seventh, component, com...   \n",
       "\n",
       "                                         Text_Lemmas  \\\n",
       "0  [common, human, skin, tumour, cause, activate,...   \n",
       "1  [HFE, mutation, analysis, hemochromatosis, pro...   \n",
       "2  [Germline, alteration, population, base, serie...   \n",
       "3  [identification, homologue, adenomatous, polyp...   \n",
       "4  [familial, deficiency, seventh, component, com...   \n",
       "\n",
       "                             SpecificDiseaseEntities  \\\n",
       "0  [adenomatous polyposis coli, APC, pilomatricom...   \n",
       "1  [hemochromatosis, Hereditary hemochromatosis, ...   \n",
       "2                                   [ovarian cancer]   \n",
       "3                                           [cancer]   \n",
       "4  [Familial deficiency of the seventh component ...   \n",
       "\n",
       "                                            ner_tags  \n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1  [0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, ...  \n",
       "2  [0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "4  [1, 2, 2, 2, 2, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, ...  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T05:25:51.326345Z",
     "iopub.status.busy": "2024-04-23T05:25:51.326079Z",
     "iopub.status.idle": "2024-04-23T05:25:51.376392Z",
     "shell.execute_reply": "2024-04-23T05:25:51.375622Z",
     "shell.execute_reply.started": "2024-04-23T05:25:51.326324Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'tokens', 'labels'],\n",
       "        num_rows: 593\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'tokens', 'labels'],\n",
       "        num_rows: 100\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'tokens', 'labels'],\n",
       "        num_rows: 100\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "# For training data\n",
    "# train_ner = train_df.rename(columns={'Text_Tokens': 'tokens', 'ner_tags': 'labels'})[['tokens', 'labels']]\n",
    "train_ner = train_df.rename(columns={'Text_Tokens': 'tokens', 'ner_tags': 'labels'})\n",
    "train_ner['id'] = train_ner.index.tolist()  # Adding 'id' column\n",
    "train_ner = train_ner[['id', 'tokens', 'labels']]\n",
    "\n",
    "# For development data\n",
    "# dev_ner = dev_df.rename(columns={'Text_Tokens': 'tokens', 'ner_tags': 'labels'})[['tokens', 'labels']]\n",
    "dev_ner = dev_df.rename(columns={'Text_Tokens': 'tokens', 'ner_tags': 'labels'})\n",
    "dev_ner['id'] = dev_ner.index.tolist()  # Adding 'id' column\n",
    "dev_ner = dev_ner[['id', 'tokens', 'labels']]\n",
    "\n",
    "# For testing data\n",
    "# test_ner = test_df.rename(columns={'Text_Tokens': 'tokens', 'ner_tags': 'labels'})[['tokens', 'labels']]\n",
    "test_ner = test_df.rename(columns={'Text_Tokens': 'tokens', 'ner_tags': 'labels'})\n",
    "test_ner['id'] = test_ner.index.tolist()  # Adding 'id' column\n",
    "test_ner = test_ner[['id', 'tokens', 'labels']]\n",
    "\n",
    "train_ner = Dataset.from_pandas(train_ner)\n",
    "dev_ner = Dataset.from_pandas(dev_ner)\n",
    "test_ner = Dataset.from_pandas(test_ner)\n",
    "\n",
    "dataset = DatasetDict({\"train\": train_ner, \"validation\": dev_ner, \"test\": test_ner})\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T05:25:51.377456Z",
     "iopub.status.busy": "2024-04-23T05:25:51.377222Z",
     "iopub.status.idle": "2024-04-23T05:25:51.395888Z",
     "shell.execute_reply": "2024-04-23T05:25:51.394992Z",
     "shell.execute_reply.started": "2024-04-23T05:25:51.377436Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']['labels'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T05:25:51.397096Z",
     "iopub.status.busy": "2024-04-23T05:25:51.396855Z",
     "iopub.status.idle": "2024-04-23T05:25:51.403670Z",
     "shell.execute_reply": "2024-04-23T05:25:51.402826Z",
     "shell.execute_reply.started": "2024-04-23T05:25:51.397075Z"
    }
   },
   "outputs": [],
   "source": [
    "label_list=[\"O\",\"B\",\"I\"]\n",
    "\n",
    "id2label = {\n",
    "    0: \"O\",\n",
    "    1: \"B\",\n",
    "    2: \"I\",\n",
    "}\n",
    "label2id = {\n",
    "    \"O\": 0,\n",
    "    \"B\": 1,\n",
    "    \"I\": 2,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NCBI Disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T05:25:51.405017Z",
     "iopub.status.busy": "2024-04-23T05:25:51.404685Z",
     "iopub.status.idle": "2024-04-23T05:25:55.644002Z",
     "shell.execute_reply": "2024-04-23T05:25:55.643138Z",
     "shell.execute_reply.started": "2024-04-23T05:25:51.404972Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Load the NCBI Disease Corpus dataset\n",
    "# dataset = load_dataset(\"ncbi_disease\")\n",
    "# # Renaming 'ner_tags' to 'label' in the train dataset\n",
    "# dataset['train'] = dataset['train'].rename_column(\"ner_tags\", \"labels\")\n",
    "\n",
    "# # Renaming 'ner_tags' to 'label' in the validation dataset\n",
    "# dataset['validation'] = dataset['validation'].rename_column(\"ner_tags\", \"labels\")\n",
    "\n",
    "# # Renaming 'ner_tags' to 'label' in the test dataset\n",
    "# dataset['test'] = dataset['test'].rename_column(\"ner_tags\", \"labels\")\n",
    "\n",
    "\n",
    "\n",
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T05:25:55.645498Z",
     "iopub.status.busy": "2024-04-23T05:25:55.645200Z",
     "iopub.status.idle": "2024-04-23T05:25:55.852347Z",
     "shell.execute_reply": "2024-04-23T05:25:55.851320Z",
     "shell.execute_reply.started": "2024-04-23T05:25:55.645468Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['common',\n",
       " 'human',\n",
       " 'skin',\n",
       " 'tumour',\n",
       " 'caused',\n",
       " 'activating',\n",
       " 'mutations',\n",
       " 'beta',\n",
       " 'catenin',\n",
       " 'WNT',\n",
       " 'signalling',\n",
       " 'orchestrates',\n",
       " 'number',\n",
       " 'developmental',\n",
       " 'programs',\n",
       " 'response',\n",
       " 'stimulus',\n",
       " 'cytoplasmic',\n",
       " 'beta',\n",
       " 'catenin',\n",
       " 'encoded',\n",
       " 'stabilized',\n",
       " 'enabling',\n",
       " 'downstream',\n",
       " 'transcriptional',\n",
       " 'activation',\n",
       " 'members',\n",
       " 'LEF',\n",
       " 'TCF',\n",
       " 'family',\n",
       " 'target',\n",
       " 'genes',\n",
       " 'beta',\n",
       " 'catenin',\n",
       " 'TCF',\n",
       " 'encodes',\n",
       " 'c',\n",
       " 'MYC',\n",
       " 'explaining',\n",
       " 'constitutive',\n",
       " 'activation',\n",
       " 'WNT',\n",
       " 'pathway',\n",
       " 'lead',\n",
       " 'cancer',\n",
       " 'particularly',\n",
       " 'colon',\n",
       " 'colon',\n",
       " 'cancers',\n",
       " 'arise',\n",
       " 'mutations',\n",
       " 'gene',\n",
       " 'encoding',\n",
       " 'adenomatous',\n",
       " 'polyposis',\n",
       " 'coli',\n",
       " 'APC',\n",
       " 'protein',\n",
       " 'required',\n",
       " 'ubiquitin',\n",
       " 'mediated',\n",
       " 'degradation',\n",
       " 'beta',\n",
       " 'catenin',\n",
       " 'small',\n",
       " 'percentage',\n",
       " 'colon',\n",
       " 'cancers',\n",
       " 'harbour',\n",
       " 'beta',\n",
       " 'catenin',\n",
       " 'stabilizing',\n",
       " 'mutations',\n",
       " 'Recently',\n",
       " 'discovered',\n",
       " 'transgenic',\n",
       " 'mice',\n",
       " 'expressing',\n",
       " 'activated',\n",
       " 'beta',\n",
       " 'catenin',\n",
       " 'predisposed',\n",
       " 'developing',\n",
       " 'skin',\n",
       " 'tumours',\n",
       " 'resembling',\n",
       " 'pilomatricomas',\n",
       " 'Given',\n",
       " 'skin',\n",
       " 'adult',\n",
       " 'mice',\n",
       " 'exhibits',\n",
       " 'signs',\n",
       " 'de',\n",
       " 'novo',\n",
       " 'hair',\n",
       " 'follicle',\n",
       " 'morphogenesis',\n",
       " 'wondered',\n",
       " 'human',\n",
       " 'pilomatricomas',\n",
       " 'originate',\n",
       " 'hair',\n",
       " 'matrix',\n",
       " 'cells',\n",
       " 'possess',\n",
       " 'beta',\n",
       " 'catenin',\n",
       " 'stabilizing',\n",
       " 'mutations',\n",
       " 'explore',\n",
       " 'cell',\n",
       " 'origin',\n",
       " 'aetiology',\n",
       " 'common',\n",
       " 'human',\n",
       " 'skin',\n",
       " 'tumour',\n",
       " 'found',\n",
       " 'nuclear',\n",
       " 'dividing',\n",
       " 'tumour',\n",
       " 'cells',\n",
       " 'providing',\n",
       " 'biochemical',\n",
       " 'evidence',\n",
       " 'pilomatricomas',\n",
       " 'derived',\n",
       " 'hair',\n",
       " 'matrix',\n",
       " 'cells',\n",
       " 'tumours',\n",
       " 'possess',\n",
       " 'mutations',\n",
       " 'affecting',\n",
       " 'amino',\n",
       " 'terminal',\n",
       " 'segment',\n",
       " 'normally',\n",
       " 'involved',\n",
       " 'phosphorylation',\n",
       " 'dependent',\n",
       " 'ubiquitin',\n",
       " 'mediated',\n",
       " 'degradation',\n",
       " 'protein',\n",
       " 'percentage',\n",
       " 'mutations',\n",
       " 'greater',\n",
       " 'human',\n",
       " 'tumours',\n",
       " 'examined',\n",
       " 'far',\n",
       " 'directly',\n",
       " 'implicates',\n",
       " 'beta',\n",
       " 'catenin',\n",
       " 'LEF',\n",
       " 'misregulation',\n",
       " 'major',\n",
       " 'cause',\n",
       " 'hair',\n",
       " 'matrix',\n",
       " 'cell',\n",
       " 'tumorigenesis',\n",
       " 'humans']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']['tokens'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T05:25:55.853817Z",
     "iopub.status.busy": "2024-04-23T05:25:55.853465Z",
     "iopub.status.idle": "2024-04-23T05:25:59.826846Z",
     "shell.execute_reply": "2024-04-23T05:25:59.826097Z",
     "shell.execute_reply.started": "2024-04-23T05:25:55.853783Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/electra-large-discriminator\")\n",
    "\n",
    "# def tokenize_function(examples):\n",
    "#     examples[\"tokens\"] = [\" \".join(tokens) for tokens in examples[\"tokens\"]]\n",
    "#     return tokenizer(examples[\"tokens\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "# tokenized_datasets = dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab41ae2c27ae457c97fc1773e6281f6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/593 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c56537862fb435cabf85096376f4b43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d627a2ecf9884a61abe28f6bca90bb02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True)\n",
    "\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[\"labels\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)  # Map tokens to their respective word.\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:  # Set the special tokens to -100.\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            elif word_idx != previous_word_idx:  # Only label the first token of a given word.\n",
    "                label_ids.append(label[word_idx])\n",
    "            else:\n",
    "                label_ids.append(-100)\n",
    "            previous_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs\n",
    "\n",
    "tokenized_datasets =dataset.map(tokenize_and_align_labels, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T05:25:59.828165Z",
     "iopub.status.busy": "2024-04-23T05:25:59.827871Z",
     "iopub.status.idle": "2024-04-23T05:25:59.834414Z",
     "shell.execute_reply": "2024-04-23T05:25:59.833479Z",
     "shell.execute_reply.started": "2024-04-23T05:25:59.828139Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 0,\n",
       " 'tokens': ['common',\n",
       "  'human',\n",
       "  'skin',\n",
       "  'tumour',\n",
       "  'caused',\n",
       "  'activating',\n",
       "  'mutations',\n",
       "  'beta',\n",
       "  'catenin',\n",
       "  'WNT',\n",
       "  'signalling',\n",
       "  'orchestrates',\n",
       "  'number',\n",
       "  'developmental',\n",
       "  'programs',\n",
       "  'response',\n",
       "  'stimulus',\n",
       "  'cytoplasmic',\n",
       "  'beta',\n",
       "  'catenin',\n",
       "  'encoded',\n",
       "  'stabilized',\n",
       "  'enabling',\n",
       "  'downstream',\n",
       "  'transcriptional',\n",
       "  'activation',\n",
       "  'members',\n",
       "  'LEF',\n",
       "  'TCF',\n",
       "  'family',\n",
       "  'target',\n",
       "  'genes',\n",
       "  'beta',\n",
       "  'catenin',\n",
       "  'TCF',\n",
       "  'encodes',\n",
       "  'c',\n",
       "  'MYC',\n",
       "  'explaining',\n",
       "  'constitutive',\n",
       "  'activation',\n",
       "  'WNT',\n",
       "  'pathway',\n",
       "  'lead',\n",
       "  'cancer',\n",
       "  'particularly',\n",
       "  'colon',\n",
       "  'colon',\n",
       "  'cancers',\n",
       "  'arise',\n",
       "  'mutations',\n",
       "  'gene',\n",
       "  'encoding',\n",
       "  'adenomatous',\n",
       "  'polyposis',\n",
       "  'coli',\n",
       "  'APC',\n",
       "  'protein',\n",
       "  'required',\n",
       "  'ubiquitin',\n",
       "  'mediated',\n",
       "  'degradation',\n",
       "  'beta',\n",
       "  'catenin',\n",
       "  'small',\n",
       "  'percentage',\n",
       "  'colon',\n",
       "  'cancers',\n",
       "  'harbour',\n",
       "  'beta',\n",
       "  'catenin',\n",
       "  'stabilizing',\n",
       "  'mutations',\n",
       "  'Recently',\n",
       "  'discovered',\n",
       "  'transgenic',\n",
       "  'mice',\n",
       "  'expressing',\n",
       "  'activated',\n",
       "  'beta',\n",
       "  'catenin',\n",
       "  'predisposed',\n",
       "  'developing',\n",
       "  'skin',\n",
       "  'tumours',\n",
       "  'resembling',\n",
       "  'pilomatricomas',\n",
       "  'Given',\n",
       "  'skin',\n",
       "  'adult',\n",
       "  'mice',\n",
       "  'exhibits',\n",
       "  'signs',\n",
       "  'de',\n",
       "  'novo',\n",
       "  'hair',\n",
       "  'follicle',\n",
       "  'morphogenesis',\n",
       "  'wondered',\n",
       "  'human',\n",
       "  'pilomatricomas',\n",
       "  'originate',\n",
       "  'hair',\n",
       "  'matrix',\n",
       "  'cells',\n",
       "  'possess',\n",
       "  'beta',\n",
       "  'catenin',\n",
       "  'stabilizing',\n",
       "  'mutations',\n",
       "  'explore',\n",
       "  'cell',\n",
       "  'origin',\n",
       "  'aetiology',\n",
       "  'common',\n",
       "  'human',\n",
       "  'skin',\n",
       "  'tumour',\n",
       "  'found',\n",
       "  'nuclear',\n",
       "  'dividing',\n",
       "  'tumour',\n",
       "  'cells',\n",
       "  'providing',\n",
       "  'biochemical',\n",
       "  'evidence',\n",
       "  'pilomatricomas',\n",
       "  'derived',\n",
       "  'hair',\n",
       "  'matrix',\n",
       "  'cells',\n",
       "  'tumours',\n",
       "  'possess',\n",
       "  'mutations',\n",
       "  'affecting',\n",
       "  'amino',\n",
       "  'terminal',\n",
       "  'segment',\n",
       "  'normally',\n",
       "  'involved',\n",
       "  'phosphorylation',\n",
       "  'dependent',\n",
       "  'ubiquitin',\n",
       "  'mediated',\n",
       "  'degradation',\n",
       "  'protein',\n",
       "  'percentage',\n",
       "  'mutations',\n",
       "  'greater',\n",
       "  'human',\n",
       "  'tumours',\n",
       "  'examined',\n",
       "  'far',\n",
       "  'directly',\n",
       "  'implicates',\n",
       "  'beta',\n",
       "  'catenin',\n",
       "  'LEF',\n",
       "  'misregulation',\n",
       "  'major',\n",
       "  'cause',\n",
       "  'hair',\n",
       "  'matrix',\n",
       "  'cell',\n",
       "  'tumorigenesis',\n",
       "  'humans'],\n",
       " 'labels': [-100,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  -100,\n",
       "  0,\n",
       "  0,\n",
       "  -100,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  -100,\n",
       "  -100,\n",
       "  0,\n",
       "  -100,\n",
       "  0,\n",
       "  0,\n",
       "  -100,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  0,\n",
       "  0,\n",
       "  -100,\n",
       "  -100,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  -100,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  -100,\n",
       "  0,\n",
       "  -100,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  -100,\n",
       "  -100,\n",
       "  0,\n",
       "  -100,\n",
       "  0,\n",
       "  -100,\n",
       "  0,\n",
       "  0,\n",
       "  -100,\n",
       "  0,\n",
       "  0,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  0,\n",
       "  0,\n",
       "  -100,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  2,\n",
       "  -100,\n",
       "  -100,\n",
       "  2,\n",
       "  1,\n",
       "  -100,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  -100,\n",
       "  -100,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  -100,\n",
       "  -100,\n",
       "  0,\n",
       "  -100,\n",
       "  -100,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  -100,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  -100,\n",
       "  -100,\n",
       "  0,\n",
       "  -100,\n",
       "  -100,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  -100,\n",
       "  -100,\n",
       "  0,\n",
       "  1,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  -100,\n",
       "  -100,\n",
       "  0,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  -100,\n",
       "  -100,\n",
       "  0,\n",
       "  -100,\n",
       "  -100,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  -100,\n",
       "  -100,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  -100,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  -100,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  -100,\n",
       "  0,\n",
       "  1,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  -100,\n",
       "  -100,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  0,\n",
       "  0,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  -100,\n",
       "  -100,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  -100,\n",
       "  -100,\n",
       "  0,\n",
       "  0,\n",
       "  -100,\n",
       "  -100,\n",
       "  0,\n",
       "  -100,\n",
       "  0,\n",
       "  -100,\n",
       "  -100,\n",
       "  -100,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  -100,\n",
       "  -100,\n",
       "  0,\n",
       "  -100],\n",
       " 'input_ids': [101,\n",
       "  2691,\n",
       "  2529,\n",
       "  3096,\n",
       "  10722,\n",
       "  20360,\n",
       "  3303,\n",
       "  2552,\n",
       "  17441,\n",
       "  14494,\n",
       "  8247,\n",
       "  4937,\n",
       "  18595,\n",
       "  2078,\n",
       "  1059,\n",
       "  3372,\n",
       "  21919,\n",
       "  4032,\n",
       "  4570,\n",
       "  2193,\n",
       "  13908,\n",
       "  3454,\n",
       "  3433,\n",
       "  19220,\n",
       "  22330,\n",
       "  14399,\n",
       "  8523,\n",
       "  7712,\n",
       "  8247,\n",
       "  4937,\n",
       "  18595,\n",
       "  2078,\n",
       "  12359,\n",
       "  27697,\n",
       "  12067,\n",
       "  13248,\n",
       "  14193,\n",
       "  2389,\n",
       "  13791,\n",
       "  2372,\n",
       "  3393,\n",
       "  2546,\n",
       "  22975,\n",
       "  2546,\n",
       "  2155,\n",
       "  4539,\n",
       "  9165,\n",
       "  8247,\n",
       "  4937,\n",
       "  18595,\n",
       "  2078,\n",
       "  22975,\n",
       "  2546,\n",
       "  4372,\n",
       "  23237,\n",
       "  1039,\n",
       "  2026,\n",
       "  2278,\n",
       "  9990,\n",
       "  9530,\n",
       "  16643,\n",
       "  8525,\n",
       "  6024,\n",
       "  13791,\n",
       "  1059,\n",
       "  3372,\n",
       "  12732,\n",
       "  2599,\n",
       "  4456,\n",
       "  3391,\n",
       "  16844,\n",
       "  16844,\n",
       "  25409,\n",
       "  13368,\n",
       "  14494,\n",
       "  4962,\n",
       "  17181,\n",
       "  16298,\n",
       "  9626,\n",
       "  24826,\n",
       "  2015,\n",
       "  26572,\n",
       "  6873,\n",
       "  6190,\n",
       "  27441,\n",
       "  9706,\n",
       "  2278,\n",
       "  5250,\n",
       "  3223,\n",
       "  1057,\n",
       "  5638,\n",
       "  15549,\n",
       "  7629,\n",
       "  19872,\n",
       "  16627,\n",
       "  8247,\n",
       "  4937,\n",
       "  18595,\n",
       "  2078,\n",
       "  2235,\n",
       "  7017,\n",
       "  16844,\n",
       "  25409,\n",
       "  7440,\n",
       "  8247,\n",
       "  4937,\n",
       "  18595,\n",
       "  2078,\n",
       "  17079,\n",
       "  18622,\n",
       "  6774,\n",
       "  14494,\n",
       "  3728,\n",
       "  3603,\n",
       "  9099,\n",
       "  16505,\n",
       "  12328,\n",
       "  14026,\n",
       "  8878,\n",
       "  8247,\n",
       "  4937,\n",
       "  18595,\n",
       "  2078,\n",
       "  3653,\n",
       "  10521,\n",
       "  19155,\n",
       "  4975,\n",
       "  3096,\n",
       "  10722,\n",
       "  20360,\n",
       "  2015,\n",
       "  15525,\n",
       "  14255,\n",
       "  21297,\n",
       "  4017,\n",
       "  7277,\n",
       "  9626,\n",
       "  2015,\n",
       "  2445,\n",
       "  3096,\n",
       "  4639,\n",
       "  12328,\n",
       "  10637,\n",
       "  5751,\n",
       "  2139,\n",
       "  24576,\n",
       "  2606,\n",
       "  1042,\n",
       "  14511,\n",
       "  25128,\n",
       "  22822,\n",
       "  8458,\n",
       "  23924,\n",
       "  19009,\n",
       "  4999,\n",
       "  2529,\n",
       "  14255,\n",
       "  21297,\n",
       "  4017,\n",
       "  7277,\n",
       "  9626,\n",
       "  2015,\n",
       "  21754,\n",
       "  2606,\n",
       "  8185,\n",
       "  4442,\n",
       "  10295,\n",
       "  8247,\n",
       "  4937,\n",
       "  18595,\n",
       "  2078,\n",
       "  17079,\n",
       "  18622,\n",
       "  6774,\n",
       "  14494,\n",
       "  8849,\n",
       "  3526,\n",
       "  4761,\n",
       "  29347,\n",
       "  3775,\n",
       "  6779,\n",
       "  2691,\n",
       "  2529,\n",
       "  3096,\n",
       "  10722,\n",
       "  20360,\n",
       "  2179,\n",
       "  4517,\n",
       "  16023,\n",
       "  10722,\n",
       "  20360,\n",
       "  4442,\n",
       "  4346,\n",
       "  16012,\n",
       "  15869,\n",
       "  3350,\n",
       "  14255,\n",
       "  21297,\n",
       "  4017,\n",
       "  7277,\n",
       "  9626,\n",
       "  2015,\n",
       "  5173,\n",
       "  2606,\n",
       "  8185,\n",
       "  4442,\n",
       "  10722,\n",
       "  20360,\n",
       "  2015,\n",
       "  10295,\n",
       "  14494,\n",
       "  12473,\n",
       "  13096,\n",
       "  5536,\n",
       "  6903,\n",
       "  5373,\n",
       "  2920,\n",
       "  6887,\n",
       "  2891,\n",
       "  8458,\n",
       "  10253,\n",
       "  13490,\n",
       "  7790,\n",
       "  1057,\n",
       "  5638,\n",
       "  15549,\n",
       "  7629,\n",
       "  19872,\n",
       "  16627,\n",
       "  5250,\n",
       "  7017,\n",
       "  14494,\n",
       "  3618,\n",
       "  2529,\n",
       "  10722,\n",
       "  20360,\n",
       "  2015,\n",
       "  8920,\n",
       "  2521,\n",
       "  3495,\n",
       "  17727,\n",
       "  19341,\n",
       "  4570,\n",
       "  8247,\n",
       "  4937,\n",
       "  18595,\n",
       "  2078,\n",
       "  3393,\n",
       "  2546,\n",
       "  28616,\n",
       "  2890,\n",
       "  24848,\n",
       "  3370,\n",
       "  2350,\n",
       "  3426,\n",
       "  2606,\n",
       "  8185,\n",
       "  3526,\n",
       "  13656,\n",
       "  29206,\n",
       "  19009,\n",
       "  4286,\n",
       "  102],\n",
       " 'token_type_ids': [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'attention_mask': [1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1]}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = tokenized_datasets['train'][0]\n",
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T05:25:59.835713Z",
     "iopub.status.busy": "2024-04-23T05:25:59.835413Z",
     "iopub.status.idle": "2024-04-23T05:25:59.870889Z",
     "shell.execute_reply": "2024-04-23T05:25:59.869849Z",
     "shell.execute_reply.started": "2024-04-23T05:25:59.835672Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "263"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenized_datasets['train'][0]['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "263"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenized_datasets['train'][0]['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqeval = evaluate.load(\"seqeval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    true_predictions = [\n",
    "        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    results = seqeval.compute(predictions=true_predictions, references=true_labels)\n",
    "    return {\n",
    "        \"precision\": results[\"overall_precision\"],\n",
    "        \"recall\": results[\"overall_recall\"],\n",
    "        \"f1\": results[\"overall_f1\"],\n",
    "        \"accuracy\": results[\"overall_accuracy\"],\n",
    "    }\n",
    "\n",
    "id2label = {\n",
    "    0: \"O\",\n",
    "    1: \"B\",\n",
    "    2: \"I\",\n",
    "\n",
    "}\n",
    "label2id = {\n",
    "    \"O\": 0,\n",
    "    \"B\": 1,\n",
    "    \"I\": 2,\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T05:25:59.872292Z",
     "iopub.status.busy": "2024-04-23T05:25:59.871953Z",
     "iopub.status.idle": "2024-04-23T05:26:03.088840Z",
     "shell.execute_reply": "2024-04-23T05:26:03.088008Z",
     "shell.execute_reply.started": "2024-04-23T05:25:59.872266Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ElectraForTokenClassification were not initialized from the model checkpoint at google/electra-large-discriminator and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForTokenClassification, TrainingArguments, Trainer\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    \"google/electra-large-discriminator\", num_labels=3, id2label=id2label, label2id=label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T05:26:03.090743Z",
     "iopub.status.busy": "2024-04-23T05:26:03.090387Z",
     "iopub.status.idle": "2024-04-23T05:26:03.096300Z",
     "shell.execute_reply": "2024-04-23T05:26:03.095297Z",
     "shell.execute_reply.started": "2024-04-23T05:26:03.090712Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 'cuda' device\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ElectraForTokenClassification(\n",
       "  (electra): ElectraModel(\n",
       "    (embeddings): ElectraEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 1024, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 1024)\n",
       "      (token_type_embeddings): Embedding(2, 1024)\n",
       "      (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): ElectraEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-23): 24 x ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=1024, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if gpu is available\n",
    "device = 'cpu' \n",
    "if torch.backends.mps.is_available():\n",
    "    device = 'mps'\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "print(f\"Using '{device}' device\")\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T05:27:42.777080Z",
     "iopub.status.busy": "2024-04-23T05:27:42.776699Z",
     "iopub.status.idle": "2024-04-23T05:27:42.788566Z",
     "shell.execute_reply": "2024-04-23T05:27:42.787301Z",
     "shell.execute_reply.started": "2024-04-23T05:27:42.777050Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./\",\n",
    "    overwrite_output_dir=True,\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=1,\n",
    "    num_train_epochs=10,\n",
    "    do_eval=True,\n",
    "    seed=12345,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_f1\",\n",
    "    greater_is_better=True,\n",
    "    report_to=\"wandb\", \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForTokenClassification\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T05:27:44.105996Z",
     "iopub.status.busy": "2024-04-23T05:27:44.105710Z",
     "iopub.status.idle": "2024-04-23T05:27:44.154177Z",
     "shell.execute_reply": "2024-04-23T05:27:44.153250Z",
     "shell.execute_reply.started": "2024-04-23T05:27:44.105972Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aryanrr/.local/lib/python3.9/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "# Set up trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-23T05:27:44.710322Z",
     "iopub.status.busy": "2024-04-23T05:27:44.710055Z",
     "iopub.status.idle": "2024-04-23T05:27:46.762065Z",
     "shell.execute_reply": "2024-04-23T05:27:46.760220Z",
     "shell.execute_reply.started": "2024-04-23T05:27:44.710299Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmichaelbrown\u001b[0m (\u001b[33msi630_hw\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/aryanrr/wandb/run-20240424_000755-mj7op6tn</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/si630_hw/huggingface/runs/mj7op6tn' target=\"_blank\">skilled-darkness-41</a></strong> to <a href='https://wandb.ai/si630_hw/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/si630_hw/huggingface' target=\"_blank\">https://wandb.ai/si630_hw/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/si630_hw/huggingface/runs/mj7op6tn' target=\"_blank\">https://wandb.ai/si630_hw/huggingface/runs/mj7op6tn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='380' max='380' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [380/380 07:05, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.167544</td>\n",
       "      <td>0.465498</td>\n",
       "      <td>0.608883</td>\n",
       "      <td>0.527623</td>\n",
       "      <td>0.930882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.140671</td>\n",
       "      <td>0.538122</td>\n",
       "      <td>0.697708</td>\n",
       "      <td>0.607611</td>\n",
       "      <td>0.942047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.115909</td>\n",
       "      <td>0.630807</td>\n",
       "      <td>0.739255</td>\n",
       "      <td>0.680739</td>\n",
       "      <td>0.958175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.116181</td>\n",
       "      <td>0.635236</td>\n",
       "      <td>0.733524</td>\n",
       "      <td>0.680851</td>\n",
       "      <td>0.957111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.102418</td>\n",
       "      <td>0.691218</td>\n",
       "      <td>0.699140</td>\n",
       "      <td>0.695157</td>\n",
       "      <td>0.965352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.102660</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.710602</td>\n",
       "      <td>0.717800</td>\n",
       "      <td>0.968011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.116270</td>\n",
       "      <td>0.683155</td>\n",
       "      <td>0.732092</td>\n",
       "      <td>0.706777</td>\n",
       "      <td>0.964112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.115089</td>\n",
       "      <td>0.740580</td>\n",
       "      <td>0.732092</td>\n",
       "      <td>0.736311</td>\n",
       "      <td>0.968631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.116212</td>\n",
       "      <td>0.741557</td>\n",
       "      <td>0.723496</td>\n",
       "      <td>0.732415</td>\n",
       "      <td>0.969074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.113088</td>\n",
       "      <td>0.744838</td>\n",
       "      <td>0.723496</td>\n",
       "      <td>0.734012</td>\n",
       "      <td>0.969694</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=380, training_loss=0.1180232098228053, metrics={'train_runtime': 431.8838, 'train_samples_per_second': 13.731, 'train_steps_per_second': 0.88, 'total_flos': 2951756444206140.0, 'train_loss': 0.1180232098228053, 'epoch': 10.0})"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-23T05:26:45.006669Z",
     "iopub.status.idle": "2024-04-23T05:26:45.007372Z",
     "shell.execute_reply": "2024-04-23T05:26:45.007175Z",
     "shell.execute_reply.started": "2024-04-23T05:26:45.007152Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.1150888130068779,\n",
       " 'eval_precision': 0.7405797101449275,\n",
       " 'eval_recall': 0.7320916905444126,\n",
       " 'eval_f1': 0.7363112391930837,\n",
       " 'eval_accuracy': 0.9686309260079752,\n",
       " 'eval_runtime': 1.8288,\n",
       " 'eval_samples_per_second': 54.682,\n",
       " 'eval_steps_per_second': 54.682,\n",
       " 'epoch': 10.0}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_numerical_predictions(predictions):\n",
    "    preds = predictions.predictions\n",
    "    preds = np.argmax(preds, axis=2)\n",
    "    labels = predictions.label_ids\n",
    "\n",
    "    true_predictions = [\n",
    "        [label_list[p] for p, l in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(preds, labels)\n",
    "    ]\n",
    "\n",
    "    numerical_predictions = [\n",
    "        [label2id[label] for label in sentence_labels]\n",
    "        for sentence_labels in true_predictions\n",
    "    ]\n",
    "    \n",
    "    return numerical_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tokens</th>\n",
       "      <th>labels</th>\n",
       "      <th>predicted_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[common, human, skin, tumour, caused, activati...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[HFE, mutations, analysis, hemochromatosis, pr...</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 2, 1, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[Germline, alterations, population, based, ser...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[Identification, homologue, adenomatous, polyp...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[Familial, deficiency, seventh, component, com...</td>\n",
       "      <td>[1, 2, 2, 2, 2, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 2, 2, 2, 2, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                             tokens  \\\n",
       "0   0  [common, human, skin, tumour, caused, activati...   \n",
       "1   1  [HFE, mutations, analysis, hemochromatosis, pr...   \n",
       "2   2  [Germline, alterations, population, based, ser...   \n",
       "3   3  [Identification, homologue, adenomatous, polyp...   \n",
       "4   4  [Familial, deficiency, seventh, component, com...   \n",
       "\n",
       "                                              labels  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1  [0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, ...   \n",
       "2  [0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4  [1, 2, 2, 2, 2, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                    predicted_labels  \n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1  [0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 2, 1, 0, 0, ...  \n",
       "2  [0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3  [0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, ...  \n",
       "4  [1, 2, 2, 2, 2, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, ...  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_predictions = trainer.predict(tokenized_datasets[\"train\"])\n",
    "train_numerical_predictions = get_numerical_predictions(train_predictions)\n",
    "\n",
    "train_df = dataset['train'].to_pandas()\n",
    "\n",
    "train_df['predicted_labels'] = train_numerical_predictions\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tokens</th>\n",
       "      <th>labels</th>\n",
       "      <th>predicted_labels</th>\n",
       "      <th>predicted_entities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[common, human, skin, tumour, caused, activati...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[adenomatous polyposis coli, pilomatricomas, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[HFE, mutations, analysis, hemochromatosis, pr...</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 2, 1, 0, 0, ...</td>\n",
       "      <td>[hemochromatosis, hemochromatosis, Hereditary ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[Germline, alterations, population, based, ser...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[ovarian cancer, cancer, ovarian cancer, ovari...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[Identification, homologue, adenomatous, polyp...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[polyposis, polyposis]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[Familial, deficiency, seventh, component, com...</td>\n",
       "      <td>[1, 2, 2, 2, 2, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1, 2, 2, 2, 2, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[Familial deficiency seventh component complem...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                             tokens  \\\n",
       "0   0  [common, human, skin, tumour, caused, activati...   \n",
       "1   1  [HFE, mutations, analysis, hemochromatosis, pr...   \n",
       "2   2  [Germline, alterations, population, based, ser...   \n",
       "3   3  [Identification, homologue, adenomatous, polyp...   \n",
       "4   4  [Familial, deficiency, seventh, component, com...   \n",
       "\n",
       "                                              labels  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1  [0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, ...   \n",
       "2  [0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4  [1, 2, 2, 2, 2, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                    predicted_labels  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1  [0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 2, 1, 0, 0, ...   \n",
       "2  [0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3  [0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, ...   \n",
       "4  [1, 2, 2, 2, 2, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                  predicted_entities  \n",
       "0  [adenomatous polyposis coli, pilomatricomas, p...  \n",
       "1  [hemochromatosis, hemochromatosis, Hereditary ...  \n",
       "2  [ovarian cancer, cancer, ovarian cancer, ovari...  \n",
       "3                             [polyposis, polyposis]  \n",
       "4  [Familial deficiency seventh component complem...  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_entities(tokens, labels):\n",
    "    entities = []\n",
    "    current_entity = []\n",
    "    for token, label in zip(tokens, labels):\n",
    "        if label == 1:  # B-label\n",
    "            if current_entity:\n",
    "                entities.append(\" \".join(current_entity))\n",
    "                current_entity = []\n",
    "            current_entity.append(token)\n",
    "        elif label == 2:  # I-label\n",
    "            if current_entity:\n",
    "                current_entity.append(token)\n",
    "            else:\n",
    "                current_entity.append(token)\n",
    "        else:  # O-label\n",
    "            if current_entity:\n",
    "                entities.append(\" \".join(current_entity))\n",
    "                current_entity = []\n",
    "    if current_entity:\n",
    "        entities.append(\" \".join(current_entity))\n",
    "    return entities\n",
    "\n",
    "train_df['predicted_entities'] = train_df.apply(lambda row: extract_entities(row['tokens'], row['predicted_labels']), axis=1)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tokens</th>\n",
       "      <th>labels</th>\n",
       "      <th>predicted_labels</th>\n",
       "      <th>predicted_entities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[Somatic, cell, selection, major, determinant,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 2, ...</td>\n",
       "      <td>[blood, dehydrogenase, enzyme deficiency, bloo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[ataxia, telangiectasia, gene, product, consti...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[Molecular, basis, Duarte, Los, Angeles, varia...</td>\n",
       "      <td>[0, 0, 1, 0, 0, 2, 2, 0, 0, 0, 1, 2, 2, 2, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 2, 0, ...</td>\n",
       "      <td>[galactosemia, galactosemia, galactosemia]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[intronic, mutation, lariat, branchpoint, sequ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, ...</td>\n",
       "      <td>[disease, disease, FED, FED, FED]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[Genetic, heterogeneity, hereditary, breast, c...</td>\n",
       "      <td>[0, 0, 1, 2, 2, 0, 0, 1, 0, 2, 2, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 1, 2, 2, 0, 0, 1, 0, 2, 2, 0, 0, 0, 0, ...</td>\n",
       "      <td>[hereditary breast cancer, hereditary, breast ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                             tokens  \\\n",
       "0   0  [Somatic, cell, selection, major, determinant,...   \n",
       "1   1  [ataxia, telangiectasia, gene, product, consti...   \n",
       "2   2  [Molecular, basis, Duarte, Los, Angeles, varia...   \n",
       "3   3  [intronic, mutation, lariat, branchpoint, sequ...   \n",
       "4   4  [Genetic, heterogeneity, hereditary, breast, c...   \n",
       "\n",
       "                                              labels  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, ...   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2  [0, 0, 1, 0, 0, 2, 2, 0, 0, 0, 1, 2, 2, 2, 0, ...   \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, ...   \n",
       "4  [0, 0, 1, 2, 2, 0, 0, 1, 0, 2, 2, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                    predicted_labels  \\\n",
       "0  [0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 2, ...   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2  [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 2, 0, ...   \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, ...   \n",
       "4  [0, 0, 1, 2, 2, 0, 0, 1, 0, 2, 2, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                  predicted_entities  \n",
       "0  [blood, dehydrogenase, enzyme deficiency, bloo...  \n",
       "1                                                 []  \n",
       "2         [galactosemia, galactosemia, galactosemia]  \n",
       "3                  [disease, disease, FED, FED, FED]  \n",
       "4  [hereditary breast cancer, hereditary, breast ...  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_predictions = trainer.predict(tokenized_datasets[\"validation\"])\n",
    "val_numerical_predictions = get_numerical_predictions(val_predictions)\n",
    "\n",
    "val_df = dataset['validation'].to_pandas()\n",
    "\n",
    "val_df['predicted_labels'] = val_numerical_predictions\n",
    "\n",
    "val_df['predicted_entities'] = val_df.apply(lambda row: extract_entities(row['tokens'], row['predicted_labels']), axis=1)\n",
    "\n",
    "val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tokens</th>\n",
       "      <th>labels</th>\n",
       "      <th>predicted_labels</th>\n",
       "      <th>predicted_entities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[Genetic, mapping, copper, toxicosis, locus, B...</td>\n",
       "      <td>[0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[copper toxicosis, copper, copper, Wilson dise...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[Molecular, analysis, APC, gene, families, ext...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[FAP, colorectal cancer, colorectal cancer, fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[European, multicenter, study, phenylalanine, ...</td>\n",
       "      <td>[0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[phenylalanine hydroxylase deficiency, Phenylk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[Disruption, splicing, regulated, CUG, binding...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 2, 1, 2, 1, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 2, 1, 2, 1, 0, 0, 0, 0, ...</td>\n",
       "      <td>[myotonic dystrophy, Myotonic dystrophy, DM, D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[Maternal, disomy, Prader, Willi, syndrome, co...</td>\n",
       "      <td>[1, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 2, 2, 2, ...</td>\n",
       "      <td>[1, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 2, 2, 1, ...</td>\n",
       "      <td>[Maternal disomy, syndrome, Maternal uniparent...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                             tokens  \\\n",
       "0   0  [Genetic, mapping, copper, toxicosis, locus, B...   \n",
       "1   1  [Molecular, analysis, APC, gene, families, ext...   \n",
       "2   2  [European, multicenter, study, phenylalanine, ...   \n",
       "3   3  [Disruption, splicing, regulated, CUG, binding...   \n",
       "4   4  [Maternal, disomy, Prader, Willi, syndrome, co...   \n",
       "\n",
       "                                              labels  \\\n",
       "0  [0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...   \n",
       "2  [0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3  [0, 0, 0, 0, 0, 0, 1, 2, 1, 2, 1, 0, 0, 0, 0, ...   \n",
       "4  [1, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 2, 2, 2, ...   \n",
       "\n",
       "                                    predicted_labels  \\\n",
       "0  [0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...   \n",
       "2  [0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3  [0, 0, 0, 0, 0, 0, 1, 2, 1, 2, 1, 0, 0, 0, 0, ...   \n",
       "4  [1, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 2, 2, 1, ...   \n",
       "\n",
       "                                  predicted_entities  \n",
       "0  [copper toxicosis, copper, copper, Wilson dise...  \n",
       "1  [FAP, colorectal cancer, colorectal cancer, fa...  \n",
       "2  [phenylalanine hydroxylase deficiency, Phenylk...  \n",
       "3  [myotonic dystrophy, Myotonic dystrophy, DM, D...  \n",
       "4  [Maternal disomy, syndrome, Maternal uniparent...  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions = trainer.predict(tokenized_datasets[\"test\"])\n",
    "test_numerical_predictions = get_numerical_predictions(test_predictions)\n",
    "\n",
    "test_df = dataset['test'].to_pandas()\n",
    "\n",
    "test_df['predicted_labels'] = test_numerical_predictions\n",
    "\n",
    "test_df['predicted_entities'] = test_df.apply(lambda row: extract_entities(row['tokens'], row['predicted_labels']), axis=1)\n",
    "\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Precision: 0.68\n",
      "Test Recall: 0.72\n",
      "Test F1 Score: 0.7\n",
      "Test Accuracy: 0.95\n"
     ]
    }
   ],
   "source": [
    "# Extract metrics from test_predictions\n",
    "precision = test_predictions[2]['test_precision']\n",
    "recall = test_predictions[2]['test_recall']\n",
    "f1 = test_predictions[2]['test_f1']\n",
    "accuracy = test_predictions[2]['test_accuracy']\n",
    "\n",
    "# Print rounded metrics\n",
    "print(\"Test Precision:\", round(precision, 2))\n",
    "print(\"Test Recall:\", round(recall, 2))\n",
    "print(\"Test F1 Score:\", round(f1, 2))\n",
    "print(\"Test Accuracy:\", round(accuracy, 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] O\n",
      "the O\n",
      "patient O\n",
      "was O\n",
      "diagnosed O\n",
      "with O\n",
      "stage O\n",
      "iv O\n",
      "lung O\n",
      "aden I\n",
      "##oca I\n",
      "##rc I\n",
      "##ino I\n",
      "##ma I\n",
      ". O\n",
      "mutation O\n",
      "analysis O\n",
      "revealed O\n",
      "a O\n",
      "mutation O\n",
      "in O\n",
      "the O\n",
      "e O\n",
      "##gf O\n",
      "##r O\n",
      "gene O\n",
      ". O\n",
      "[SEP] O\n"
     ]
    }
   ],
   "source": [
    "# Define the input text\n",
    "input_text = \"The patient was diagnosed with stage IV lung adenocarcinoma. Mutation analysis revealed a mutation in the EGFR gene.\"\n",
    "\n",
    "# Tokenize the input text\n",
    "inputs = tokenizer(input_text, return_tensors=\"pt\")\n",
    "\n",
    "# Move input tensors to the same device as the model\n",
    "inputs = {key: tensor.to(model.device) for key, tensor in inputs.items()}\n",
    "\n",
    "# Move the model to the same device as the input tensors\n",
    "model.to(inputs[\"input_ids\"].device)\n",
    "\n",
    "# Make predictions\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "# Get the predicted labels\n",
    "predictions = torch.argmax(outputs.logits, dim=2)\n",
    "\n",
    "# Map label IDs to labels\n",
    "label_map = {0: \"O\", 1: \"B\", 2: \"I\"}\n",
    "predicted_labels = [label_map[label_id] for label_id in predictions[0].tolist()]\n",
    "\n",
    "# Print tokenized input text along with predicted labels\n",
    "for token, label in zip(tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"].tolist()[0]), predicted_labels):\n",
    "    print(token, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(\"630_train_predictions.csv\", index=False)\n",
    "val_df.to_csv(\"630_val_predictions.csv\", index=False)\n",
    "test_df.to_csv(\"630_test_predictions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 4725730,
     "sourceId": 8020011,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30673,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
